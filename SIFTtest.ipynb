{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2  \n",
    "import numpy as np  \n",
    "#import pdb  \n",
    "#pdb.set_trace()#turn on the pdb prompt  \n",
    "  \n",
    "#read image  \n",
    "img = cv2.imread('7elevenLogo.jpg',cv2.IMREAD_COLOR)  \n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) \n",
    "cv2.threshold(gray,127,255,cv2.THRESH_BINARY)\n",
    "cv2.imshow('origin',img); \n",
    "  \n",
    "#SIFT  \n",
    "detector = cv2.SIFT()  \n",
    "keypoints = detector.detect(gray,None)  \n",
    "img = cv2.drawKeypoints(gray,keypoints)  \n",
    "# img = cv2.drawKeypoints(gray,keypoints,flags = cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)  \n",
    "# print type(keypoints[0])\n",
    "cv2.imshow('test',img);  \n",
    "cv2.waitKey(0)  \n",
    "cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read image  \n",
    "img = cv2.imread('simitsu2.jpg',cv2.IMREAD_COLOR)  \n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) \n",
    "cv2.threshold(gray,127,255,cv2.THRESH_BINARY)\n",
    "cv2.imshow('origin',img); \n",
    "  \n",
    "#SIFT  \n",
    "detector = cv2.SIFT()  \n",
    "keypoints = detector.detect(gray,None)  \n",
    "# img = cv2.drawKeypoints(gray,keypoints)  \n",
    "img = cv2.drawKeypoints(gray,keypoints,flags = cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)  \n",
    "cv2.imshow('test',img);  \n",
    "cv2.waitKey(0)  \n",
    "cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 畫出match的畫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def drawMatches(img1, kp1, img2, kp2, matches):\n",
    "    \"\"\"\n",
    "    My own implementation of cv2.drawMatches as OpenCV 2.4.9\n",
    "    does not have this function available but it's supported in\n",
    "    OpenCV 3.0.0\n",
    "\n",
    "    This function takes in two images with their associated \n",
    "    keypoints, as well as a list of DMatch data structure (matches) \n",
    "    that contains which keypoints matched in which images.\n",
    "\n",
    "    An image will be produced where a montage is shown with\n",
    "    the first image followed by the second image beside it.\n",
    "\n",
    "    Keypoints are delineated with circles, while lines are connected\n",
    "    between matching keypoints.\n",
    "\n",
    "    img1,img2 - Grayscale images\n",
    "    kp1,kp2 - Detected list of keypoints through any of the OpenCV keypoint \n",
    "              detection algorithms\n",
    "    matches - A list of matches of corresponding keypoints through any\n",
    "              OpenCV keypoint matching algorithm\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a new output image that concatenates the two images together\n",
    "    # (a.k.a) a montage\n",
    "    rows1 = img1.shape[0]\n",
    "    cols1 = img1.shape[1]\n",
    "    rows2 = img2.shape[0]\n",
    "    cols2 = img2.shape[1]\n",
    "\n",
    "    out = np.zeros((max([rows1,rows2]),cols1+cols2,3), dtype='uint8')\n",
    "\n",
    "    # Place the first image to the left\n",
    "    out[:rows1,:cols1] = np.dstack([img1, img1, img1])\n",
    "\n",
    "    # Place the next image to the right of it\n",
    "    out[:rows2,cols1:] = np.dstack([img2, img2, img2])\n",
    "\n",
    "    # For each pair of points we have between both images\n",
    "    # draw circles, then connect a line between them\n",
    "    for mat in matches:\n",
    "\n",
    "        # Get the matching keypoints for each of the images\n",
    "        img1_idx = mat.queryIdx\n",
    "        img2_idx = mat.trainIdx\n",
    "\n",
    "        # x - columns\n",
    "        # y - rows\n",
    "        (x1,y1) = kp1[img1_idx].pt\n",
    "        (x2,y2) = kp2[img2_idx].pt\n",
    "\n",
    "        # Draw a small circle at both co-ordinates\n",
    "        # radius 4\n",
    "        # colour blue\n",
    "        # thickness = 1\n",
    "        cv2.circle(out, (int(x1),int(y1)), 4, (255, 0, 0), 1)   \n",
    "        cv2.circle(out, (int(x2)+cols1,int(y2)), 4, (255, 0, 0), 1)\n",
    "\n",
    "        # Draw a line in between the two points\n",
    "        # thickness = 1\n",
    "        # colour blue\n",
    "        cv2.line(out, (int(x1),int(y1)), (int(x2)+cols1,int(y2)), (255, 0, 0), 1)\n",
    "\n",
    "\n",
    "    # Show the image\n",
    "    cv2.imshow('Matched Features', out)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyWindow('Matched Features')\n",
    "\n",
    "    # Also return the image if you'd like a copy\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 比對兩張圖像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img1 = cv2.imread('simitsu1.jpg',0)          # queryImage\n",
    "img2 = cv2.imread('simitsu2.jpg',0) # trainImage\n",
    "\n",
    "# Initiate SIFT detector\n",
    "orb = cv2.ORB()\n",
    "\n",
    "# find the keypoints and descriptors with SIFT\n",
    "kp1, des1 = orb.detectAndCompute(img1,None)\n",
    "kp2, des2 = orb.detectAndCompute(img2,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<matplotlib.image.AxesImage at 0xe5f5780>, None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create BFMatcher object\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "# Match descriptors.\n",
    "matches = bf.match(des1,des2)\n",
    "\n",
    "# Sort them in the order of their distance.\n",
    "matches = sorted(matches, key = lambda x:x.distance)\n",
    "\n",
    "# Draw first 10 matches.\n",
    "img3 = drawMatches(img1,kp1,img2,kp2,matches[:10])\n",
    "\n",
    "plt.imshow(img3),plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 利用sift進行比對"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matches... 191\n",
      "good 19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2  \n",
    "import scipy as sp  \n",
    "  \n",
    "img1 = cv2.imread('7elevenLogo.jpg',0) # queryImage  \n",
    "img2 = cv2.imread('7elevenTest2.jpg',0) # trainImage  \n",
    "  \n",
    "# Initiate SIFT detector  \n",
    "sift = cv2.SIFT()  \n",
    "  \n",
    "# find the keypoints and descriptors with SIFT  \n",
    "kp1, des1 = sift.detectAndCompute(img1,None)  \n",
    "kp2, des2 = sift.detectAndCompute(img2,None)  \n",
    "  \n",
    "# FLANN parameters  \n",
    "FLANN_INDEX_KDTREE = 0  \n",
    "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)  \n",
    "search_params = dict(checks=50)   # or pass empty dictionary  \n",
    "flann = cv2.FlannBasedMatcher(index_params,search_params)  \n",
    "matches = flann.knnMatch(des1,des2,k=2)  \n",
    "  \n",
    "print 'matches...',len(matches)  \n",
    "# Apply ratio test  \n",
    "good = []  \n",
    "for m,n in matches:  \n",
    "    if m.distance < 0.75*n.distance:  \n",
    "        good.append(m)  \n",
    "print 'good',len(good)  \n",
    "# #####################################  \n",
    "# visualization  \n",
    "h1, w1 = img1.shape[:2]  \n",
    "h2, w2 = img2.shape[:2]  \n",
    "view = sp.zeros((max(h1, h2), w1 + w2, 3), sp.uint8)  \n",
    "view[:h1, :w1, 0] = img1  \n",
    "view[:h2, w1:, 0] = img2  \n",
    "view[:, :, 1] = view[:, :, 0]  \n",
    "view[:, :, 2] = view[:, :, 0]  \n",
    "  \n",
    "for m in good:  \n",
    "    # draw the keypoints  \n",
    "    # print m.queryIdx, m.trainIdx, m.distance  \n",
    "    color = tuple([sp.random.randint(0, 255) for _ in xrange(3)])  \n",
    "    #print 'kp1,kp2',kp1,kp2  \n",
    "    cv2.line(view, (int(kp1[m.queryIdx].pt[0]), int(kp1[m.queryIdx].pt[1])) , (int(kp2[m.trainIdx].pt[0] + w1), int(kp2[m.trainIdx].pt[1])), color)  \n",
    "  \n",
    "cv2.imshow(\"view\", view)  \n",
    "cv2.waitKey()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 利用scipy比對"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matches... 191\n",
      "good 11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#coding=utf-8 \n",
    "import cv2 \n",
    "import scipy as sp \n",
    "  \n",
    "img1 = cv2.imread('7elevenLogo.jpg',0) # queryImage \n",
    "img2 = cv2.imread('E1.png',0) # trainImage \n",
    "  \n",
    "# Initiate SIFT detector \n",
    "sift = cv2.SIFT() \n",
    "  \n",
    "# find the keypoints and descriptors with SIFT \n",
    "kp1, des1 = sift.detectAndCompute(img1,None) \n",
    "kp2, des2 = sift.detectAndCompute(img2,None) \n",
    "  \n",
    "# FLANN parameters \n",
    "FLANN_INDEX_KDTREE = 0\n",
    "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5) \n",
    "search_params = dict(checks=50)  # or pass empty dictionary \n",
    "flann = cv2.FlannBasedMatcher(index_params,search_params) \n",
    "matches = flann.knnMatch(des1,des2,k=2) \n",
    "  \n",
    "print 'matches...',len(matches) \n",
    "# Apply ratio test \n",
    "good = [] \n",
    "for m,n in matches: \n",
    "    if m.distance < 0.75*n.distance: \n",
    "        good.append(m) \n",
    "print 'good',len(good) \n",
    "# ##################################### \n",
    "# visualization \n",
    "h1, w1 = img1.shape[:2] \n",
    "h2, w2 = img2.shape[:2] \n",
    "view = sp.zeros((max(h1, h2), w1 + w2, 3), sp.uint8) \n",
    "view[:h1, :w1, 0] = img1 \n",
    "view[:h2, w1:, 0] = img2 \n",
    "view[:, :, 1] = view[:, :, 0] \n",
    "view[:, :, 2] = view[:, :, 0] \n",
    "  \n",
    "for m in good: \n",
    "    #draw the keypoints \n",
    "    # print m.queryIdx, m.trainIdx, m.distance \n",
    "    color = tuple([sp.random.randint(0, 255) for _ in xrange(3)]) \n",
    "    ##print 'kp1,kp2',kp1,kp2 \n",
    "    cv2.line(view, (int(kp1[m.queryIdx].pt[0]), int(kp1[m.queryIdx].pt[1])) , (int(kp2[m.trainIdx].pt[0] + w1), int(kp2[m.trainIdx].pt[1])), color) \n",
    "  \n",
    "cv2.imshow(\"view\", view) \n",
    "cv2.waitKey() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 儲存點特徵準備訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import cPickle\n",
    "\n",
    "img = cv2.imread('car.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "sift = cv2.SIFT()\n",
    "kp = sift.detect(gray, None)\n",
    "img = cv2.drawKeypoints(img, keypoints = kp)\n",
    "\n",
    "index = []\n",
    "\n",
    "for point in kp:\n",
    "    temp = (point.pt, point.size, point.angle, point.response, point.octave, \n",
    "            point.class_id) \n",
    "    index.append(temp)\n",
    "\n",
    "## Put the keypoints into a File\n",
    "\n",
    "f = open(\"keypoints.txt\", \"w\")\n",
    "f.write(cPickle.dumps(index))\n",
    "f.close()\n",
    "cv2.imwrite('sift_keypoints.jpg', img)\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
